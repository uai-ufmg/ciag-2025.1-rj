{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgF3qLus-Fve"
   },
   "source": [
    "# Transformers\n",
    "\n",
    "## Encoder-Decoder Transformers\n",
    "\n",
    "Neste notebook, iremos trabalhar e entender um pouco mais dos componentes essencias que compõem a parte de *decoder* de um* Transformers*, além de utilizar a arquitetura completa para realizar a previsão de litologia de perfis de poço (séries temporais)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nbproxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNA3Fxtp-Fvj"
   },
   "source": [
    "### Revisão rápida dos conceitos da última aula\n",
    "\n",
    "O mecanismo de atenção utilizado por um *Transformers* se dá através do processo chamado de *scaled dot-product*, tendo a seguinte fórmula:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}) = \\text{Softmax}\\left[\\dfrac{\\mathbf{Q}\\mathbf{K^T}}{d\\_model}\\right] \\mathbf{V}\n",
    "$$\n",
    "\n",
    "Além disso, é proposto um aprimoramento desse conceito de atenção através do uso de múltiplas **cabeças de atenção**, um análogo ao uso de múltiplos filtros convolucionais em uma camada convolucional de uma rede CNN.\n",
    "\n",
    "$$\n",
    "\\text{MHA}(Q, K, V) = \\text{concat}\\left[H_1, \\dots, H_n\\right]\\mathbf{W^{(o)}} \\text{ , onde } H_i = Attention(Q\\mathbf{W^{(q)}_i}, K\\mathbf{W^{(k)}_i}, V\\mathbf{W^{(v)}_i})\n",
    "$$\n",
    "\n",
    "O mecanismo de atenção MHA é usado em diversas regiões do nosso transformer, tanto no *encoder* quanto no *decoder*. Durante o *encoder*, utilizamos o que é chamado de **self-attention**, formulado por $\\text{MHA}(X, X, X)$. Já no *decoder* utilizamos um **masked self-attention**, que opera identicamente ao **self-attention** visto anteriormente, porém agora multiplicamos a atenção por uma máscara binária, suprimindo algumas entradas da matriz de atenção; bem como um **cross-attention**, onde temos a formulação $\\text{MHA}(Q, K, V)$ usual, onde $Q$ é informado pelo *decoder* e $K, V$ pelo *encoder*.\n",
    "\n",
    "A partir da imagem a seguir, podemos observar a relação e utilidade desses diversos blocos ao longo de um *Transformers*:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img width=400 src=\"https://github.com/ThiagoPoppe/ciag2024/blob/main/imagens/transformers/transformers.png?raw=true\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAhKvVH--Fvl"
   },
   "source": [
    "Como fazemos tudo isso em PyTorch? Utilizamos o módulo `nn.Transformer`, cuja documentação pode ser acessada [aqui](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)!\n",
    "\n",
    "> Manipulando as máscaras de atenção do *encoder* e *decoder*, podemos adaptar esse módulo para suportar diversas tarefas relacionadas com sequência (*many-to-one*, *one-to-many*, *many-to-many*), respeitando ou não a sequencialidade e o viés temporal da entrada.\n",
    "\n",
    "- **Importante:** Note que a camada de *Positional Encoding* e *Embedding* não fazem parte do módulo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVFHqU9N-Fvl",
    "outputId": "7780f3ff-5633-42b2-d373-4bee1b323afc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "transformer = nn.Transformer(d_model=512, nhead=8, dim_feedforward=2048, activation='gelu',\n",
    "                             num_encoder_layers=1, num_decoder_layers=1, batch_first=True)\n",
    "\n",
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omUXtDvx-Fvn",
    "outputId": "d6ad58ac-f66b-4565-a7b8-62792e0ac4f9"
   },
   "outputs": [],
   "source": [
    "num_params = sum(p.numel() for p in transformer.parameters() if p.requires_grad == True)\n",
    "print('Número total de parâmetros:', num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh7xg00N-Fvo"
   },
   "source": [
    "Iremos passar apenas vetores aleatórios para observar o comportamento da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0F_ptHw-Fvp",
    "outputId": "e6e0142f-0e71-45a6-edbd-43d8f51c80a6"
   },
   "outputs": [],
   "source": [
    "src = torch.rand((4, 16, 512))\n",
    "tgt = torch.rand((4, 16, 512))\n",
    "out = transformer(src, tgt)\n",
    "\n",
    "print('Dimensão da saída:', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install sentencepiece\n",
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Muq30VRQDt-J"
   },
   "source": [
    "## Tradução utilizando *Transformers*\n",
    "\n",
    "Agora, vamos implementar um modelo `encoder-decoder` para tradução. Esse tipo de modelo recebe uma sequência na entrada, e gera uma nova sequência de saída, que é naturalmente relacionada à entrada.\n",
    "\n",
    "O dataset `IWSLT 2017` será usado para treinarmos um modelo que traduz do inglês para o francês. Lembre-se que os dados de texto precisam ser tokenizados, para que o modelo possa compreendê-los como números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1V7-IriJLOMd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "dataset = load_dataset(\"iwslt2017\", \"iwslt2017-en-fr\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "\n",
    "def tokenize_data(example):\n",
    "    src = tokenizer(example[\"translation\"][\"en\"], truncation=True, padding=\"max_length\", max_length=50, return_tensors=\"pt\")\n",
    "    tgt = tokenizer(example[\"translation\"][\"fr\"], truncation=True, padding=\"max_length\", max_length=50, return_tensors=\"pt\")\n",
    "    return { \"src\": src.input_ids.squeeze(0), \"tgt\": tgt.input_ids.squeeze(0) }\n",
    "\n",
    "dataset = dataset.map(tokenize_data, remove_columns=[\"translation\"])\n",
    "\n",
    "print(len(dataset[\"train\"][\"src\"]), len(dataset[\"train\"][\"tgt\"])) # devem ter o mesmo tamanho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wycTB1VPUmXb"
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = torch.tensor(self.data[idx][\"src\"], dtype=torch.long)\n",
    "        tgt = torch.tensor(self.data[idx][\"tgt\"], dtype=torch.long)\n",
    "        return src, tgt\n",
    "\n",
    "train_data = TranslationDataset(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testabdo o Dataset\n",
    "for src, tgt in train_data:\n",
    "    print(type(src), type(tgt))\n",
    "    print(src.shape, tgt.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\" Código baseado de https://pytorch.org/tutorials/beginner/transformer_tutorial.html \"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)  # fazendo com que \"pe\" seja um buffer (variável não treinável)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.shape[1]]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7ksYxp8SzVr"
   },
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9qDKbOtSxS7"
   },
   "outputs": [],
   "source": [
    "has_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if has_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4LoR75oTlxM"
   },
   "source": [
    "1. Implemente o modelo `TransformerTranslator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKEe6WhyPixb"
   },
   "outputs": [],
   "source": [
    "class TransformerTranslator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size=512, num_heads=8, num_layers=6, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # Implemente aqui sua solução\n",
    "\n",
    "        # defina o pad_index com o tokenizer\n",
    "        # faça o embedding\n",
    "        # faça o positional encoding\n",
    "        # defina o Transformer (use nn.Transformer c/ batch_first=True)\n",
    "        # faça a camada final - linnear\n",
    "        \n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # Implemente aqui sua solução\n",
    "\n",
    "        # defina o src_mask e o tgt_mask -> deve ter tamanhos (batch_size, seq_length) -> use a função '_generate_square_subsequent_mask'\n",
    "        # defina o src_emb e o tgt_embed -> deve ter tamanhos (batch_size, seq_length)\n",
    "        # faça  embedding + p.e.\n",
    "        # passe para o Transformer que vc definiu no init\n",
    "        # passe pela camada final\n",
    "        \n",
    "\n",
    "     def _generate_square_subsequent_mask(self, sz):\n",
    "        return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_M49HmhvTv4C"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = TransformerTranslator(vocab_size=tokenizer.vocab_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad == True)\n",
    "print('Número de parâmetros do nosso modelo:', n_params)\n",
    "\n",
    "print('\\nComponentes do modelo final:')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEJFmZ8LVEcG"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for src, tgt in dataloader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt[:, :-1])  # Shifted tgt para treinamento\n",
    "        loss = criterion(output.view(-1, tokenizer.vocab_size), tgt[:, 1:].reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBq87dTSVEWE"
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTETYrvz-Fvq"
   },
   "source": [
    "## Previsão de litologia utilizando *Transformers*\n",
    "\n",
    "Iremos agora realizar um exercício prático do que desenvolvemos até então em um contexto geológico, através da previsão de litologia dado um conjunto de séries temporais como entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLAcc3XM-Fvq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lithology_keys = {\n",
    "    0: 'Sandstone',\n",
    "    1: 'Sandstone/Shale',\n",
    "    2: 'Shale',\n",
    "    3: 'Marl',\n",
    "    4: 'Dolomite',\n",
    "    5: 'Limestone',\n",
    "    6: 'Chalk',\n",
    "    7: 'Halite',\n",
    "    8: 'Anhydrite',\n",
    "    9: 'Tuff',\n",
    "    10: 'Coal',\n",
    "    11: 'Basement'\n",
    "}\n",
    "\n",
    "lithology_numbers = {\n",
    "    30000: 0,\n",
    "    65030: 1,\n",
    "    65000: 2,\n",
    "    80000: 3,\n",
    "    74000: 4,\n",
    "    70000: 5,\n",
    "    70032: 6,\n",
    "    88000: 7,\n",
    "    86000: 8,\n",
    "    99000: 9,\n",
    "    90000: 10,\n",
    "    93000: 11\n",
    "}\n",
    "\n",
    "def process_data(df):\n",
    "    interested = ['WELL', 'FORCE_2020_LITHOFACIES_LITHOLOGY', 'GR', 'NPHI', 'RHOB', 'DTC']\n",
    "    df = df[interested]\n",
    "\n",
    "    df = df.rename(columns={'FORCE_2020_LITHOFACIES_LITHOLOGY' : 'CLASS'})\n",
    "    df['CLASS'] = df['CLASS'].map(lithology_numbers)\n",
    "\n",
    "    df = df[['WELL', 'GR', 'NPHI', 'RHOB', 'DTC', 'CLASS']]\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIgJZQjj-Fvr"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/pgeoprj/ciag2023/datasets/force_dataset/train.csv', sep=';')\n",
    "test_df = pd.read_csv('/pgeoprj/ciag2023/datasets/force_dataset/hidden_test.csv', sep=';')\n",
    "\n",
    "train_df = process_data(train_df)\n",
    "test_df = process_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtmbgpvq-Fvr",
    "outputId": "c82051d4-3875-45a3-cee8-69b0d1a03579"
   },
   "outputs": [],
   "source": [
    "print('Dimensão dos dados de treino:', train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4iuj7l8E-Fvr",
    "outputId": "db3ce4af-9c17-445b-a113-ff5e90d27ca3"
   },
   "outputs": [],
   "source": [
    "train_df[['GR', 'NPHI', 'RHOB', 'DTC']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKKxR3LF-Fvs",
    "outputId": "0bd30101-52c4-4fe9-d65e-782bcb197048"
   },
   "outputs": [],
   "source": [
    "print('Dimensão dos dados de teste:', test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VciyhT1A-Fvs",
    "outputId": "250b3f87-56df-4a2f-dea3-819380d7e5d5"
   },
   "outputs": [],
   "source": [
    "test_df[['GR', 'NPHI', 'RHOB', 'DTC']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq_pah_K-Fvs"
   },
   "source": [
    "Visualização simples da distribuição de classes em ambos conjuntos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUCg_22Y-Fvs",
    "outputId": "4a1fe1ab-2007-41d1-eff3-153ec4679fe5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_names = []\n",
    "train_percentage = []\n",
    "train_counts = train_df['CLASS'].value_counts()\n",
    "\n",
    "test_names = []\n",
    "test_percentage = []\n",
    "test_counts = test_df['CLASS'].value_counts()\n",
    "\n",
    "for item in train_counts.items():\n",
    "    train_names.append(lithology_keys[item[0]])\n",
    "    train_percentage.append(100 * float(item[1])/train_df.shape[0])\n",
    "\n",
    "for item in test_counts.items():\n",
    "    test_names.append(lithology_keys[item[0]])\n",
    "    test_percentage.append(100 * float(item[1])/test_df.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "\n",
    "ax[0].set_title('Train set')\n",
    "ax[0].bar(x=np.arange(len(train_names)), height=train_percentage)\n",
    "ax[0].set_xticks(np.arange(len(train_names)))\n",
    "ax[0].set_xticklabels(train_names, rotation=45)\n",
    "\n",
    "ax[1].set_title('Hidden test set')\n",
    "ax[1].bar(x=np.arange(len(test_names)), height=test_percentage)\n",
    "ax[1].set_xticks(np.arange(len(test_names)))\n",
    "ax[1].set_xticklabels(test_names, rotation=45)\n",
    "\n",
    "fig.supylabel('Lithology presence (\\%)')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiXPNDG7-Fvs"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FORCE(Dataset):\n",
    "    def __init__(self, dataframe, window_size = 50):\n",
    "        # Convert dataframe to NumPy array\n",
    "        self.data_array = dataframe.drop(columns=['WELL']).values\n",
    "        self.groups = dataframe['WELL'].values\n",
    "        self.window_size = window_size\n",
    "        self.group_indices = self.compute_group_indices()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.group_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        group_idx, data_idx = self.group_indices[idx]\n",
    "        sequence_ = self.data_array[data_idx:data_idx+self.window_size]\n",
    "        sequence = sequence_[:,:-1]\n",
    "        label = sequence_[:,-1]\n",
    "\n",
    "        sequence = (sequence - sequence.mean())/sequence.std()\n",
    "\n",
    "        return torch.from_numpy(sequence).to(torch.float32), torch.from_numpy(label).to(torch.long)\n",
    "\n",
    "    def compute_group_indices(self):\n",
    "        unique_groups, group_counts = np.unique(self.groups, return_counts=True)\n",
    "        group_indices = []\n",
    "        start_idx = 0\n",
    "        for group, count in zip(unique_groups, group_counts):\n",
    "            end_idx = start_idx + count - self.window_size - 1\n",
    "            indices = [(i, idx) for i, idx in enumerate(range(start_idx, end_idx))]\n",
    "            group_indices.extend(indices)\n",
    "            start_idx = end_idx\n",
    "        return group_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-n2uQQU-Fvt",
    "outputId": "30208505-21a0-44d9-d2f5-24d1883cc20a"
   },
   "outputs": [],
   "source": [
    "window_size = 50\n",
    "train_dataset = FORCE(train_df, window_size)\n",
    "test_dataset = FORCE(test_df, window_size)\n",
    "\n",
    "print('Número de dados de treino:', len(train_dataset))\n",
    "print('Número de dados de teste:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UzwlRIUh-Fvt",
    "outputId": "fa3cac97-4ce7-4860-d644-99371f0cc071"
   },
   "outputs": [],
   "source": [
    "X, y = train_dataset[0]\n",
    "print('Dimensão das features:', X.shape)\n",
    "print('Dimensão das anotações:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\" Código baseado de https://pytorch.org/tutorials/beginner/transformer_tutorial.html \"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)  # fazendo com que \"pe\" seja um buffer (variável não treinável)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.shape[1]]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-7Q9KPLUQSE"
   },
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35yoYCvwUFaS"
   },
   "source": [
    "2. Implemente o modelo `LithologyTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwhNSl77-Fvt"
   },
   "outputs": [],
   "source": [
    "class LithologyTransformer(nn.Module):\n",
    "    def __init__(self, input_size, output_size, d_model, nhead,\n",
    "                 dim_feedforward, norm_first, num_encoder_layers, num_decoder_layers):\n",
    "        super().__init__()\n",
    "        #Ioplemente aqui sua solução\n",
    "\n",
    "        # faça o embedding\n",
    "        # defina o decoder_embedding\n",
    "        # defina o positional encoding \n",
    "        # defina o Transformer (use nn.Transformer c/ batch_first=True)\n",
    "        # faça a camada final (classifier) - linnear\n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        # Implemente aqui sua solução\n",
    "\n",
    "        # faça  embedding + p.e.\n",
    "        # defina o tgt_mask -> use a função 'self.transformer.generate_square_subsequent_mask'\n",
    "        # passe para o Transformer que vc definiu no init\n",
    "        # passe pela camada final\n",
    "\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0ZC9Zy9-Fvt",
    "outputId": "2017d61b-1f64-49e7-ddca-85a2e0320b38"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "d_model = 8\n",
    "batch_size = 1024\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True, shuffle=False)\n",
    "\n",
    "model = LithologyTransformer(input_size=4, output_size=12, d_model=d_model, nhead=4, dim_feedforward=16,\n",
    "                             norm_first=False, num_encoder_layers=1, num_decoder_layers=1)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad == True)\n",
    "print('Número de parâmetros do nosso modelo:', n_params)\n",
    "\n",
    "print('\\nComponentes do modelo final:')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ik8VoOu6-Fvt"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Shiftando o target para a direita (inserção do token <sos>)\n",
    "        sos = torch.full((batch_size, 1), fill_value=12).to(device)\n",
    "        tgt = torch.cat([sos, y], dim=1)\n",
    "\n",
    "        outputs = model(X, tgt)\n",
    "        outputs = outputs[:, :-1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs.transpose(1, 2), y)  # a loss function espera que a saída do modelo seja (batch_size, out_size, seq_lengh)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        if (batch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch}/{num_epochs}], Batch [{batch+1}/{len(dataloader)}] -> batch loss: {loss.item():.5f}')\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "f18934890476496da8a9c51de5093dd0"
     ]
    },
    "id": "2Nh6NzxR-Fvt",
    "outputId": "41842698-a2c5-486e-848d-f800a5a48c7d"
   },
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = train_epoch(model, train_dataloader, optimizer, criterion)\n",
    "\n",
    "    print(f'Epoch [{epoch}/{num_epochs}] -> mean epoch loss: {epoch_loss:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IynsZDLr-Fvu"
   },
   "source": [
    "### Avaliando a performance da rede em dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DW_xdueC-Fvu"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    predictions = torch.zeros(len(dataloader), batch_size, window_size).to(device)\n",
    "    labels = torch.zeros_like(predictions)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            preds = torch.full((batch_size, 1), fill_value=12).to(device)\n",
    "            for i in range(X.shape[1]):\n",
    "                outputs = model(X, preds)\n",
    "                last_pred = outputs.argmax(dim=-1)[:, -1].unsqueeze(1)\n",
    "\n",
    "                preds = torch.cat([preds, last_pred], dim=1)\n",
    "\n",
    "            loss = criterion(outputs.transpose(1, 2), y)  # a loss function espera que a saída do modelo seja (batch_size, out_size, seq_lengh)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions[batch] = outputs.argmax(dim=-1)\n",
    "            labels[batch] = y\n",
    "\n",
    "    total_loss /= len(dataloader)\n",
    "    return total_loss, predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "028a159ca52a4575b9dcac44bd4ba7cc"
     ]
    },
    "id": "i7pMqUwc-Fvu",
    "outputId": "51109a74-7d8f-4e9a-f3a8-0749884733f3"
   },
   "outputs": [],
   "source": [
    "total_loss, predictions, labels = evaluate(model, test_dataloader, criterion)\n",
    "\n",
    "print(f'Mean hidden test loss: {total_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIif8Nez-Fvu",
    "outputId": "8316c685-484d-4083-dce1-b538639855a5"
   },
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy, Precision, Recall, ConfusionMatrix\n",
    "\n",
    "acc = Accuracy(task = 'multiclass', num_classes = 12).to(device)\n",
    "prec = Precision(task = 'multiclass', average='macro', num_classes = 12).to(device)\n",
    "recall = Recall(task = 'multiclass', average='macro', num_classes = 12).to(device)\n",
    "\n",
    "print(f'Acurácia: {(100*acc(labels, predictions)):.2f}%')\n",
    "print(f'Precisão: {(100*prec(labels, predictions)):.2f}%')\n",
    "print(f'Recall: {(100*recall(labels, predictions)):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlnVul-F-Fvu"
   },
   "source": [
    "Computando uma matriz de confusão para verificarmos a qualidade do nosso modelo nos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcDJBLQ0-Fvu",
    "outputId": "7c77593c-a8a7-4de9-f94f-838f6a19b95d"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = ConfusionMatrix(task = 'multiclass', num_classes = 12).to(device)\n",
    "cm = confusion_matrix(labels, predictions).cpu()\n",
    "cm = (cm.float() / cm.sum(axis=1)[:, np.newaxis]).nan_to_num()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', xticklabels=lithology_keys.values(), yticklabels=lithology_keys.values())\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show(block=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
